{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercise5-gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnJg-jEHGqQR",
        "outputId": "3de1e37b-765d-4f7c-a2a4-cceba928f8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rChiB3kK_HMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b464fb73-0184-4724-fcce-3a4a8429a432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter-0; D_loss: 1.4635330438613892; G_loss: 2.1223740577697754\n",
            "Iter-1000; D_loss: 0.007852480746805668; G_loss: 8.235454559326172\n",
            "Iter-2000; D_loss: 0.0371272899210453; G_loss: 5.607226371765137\n",
            "Iter-3000; D_loss: 0.0952954813838005; G_loss: 4.773682594299316\n",
            "Iter-4000; D_loss: 0.16303715109825134; G_loss: 4.865339756011963\n",
            "Iter-5000; D_loss: 0.15661019086837769; G_loss: 4.641195774078369\n",
            "Iter-6000; D_loss: 0.39188510179519653; G_loss: 4.286818027496338\n",
            "Iter-7000; D_loss: 0.4969128370285034; G_loss: 3.3988757133483887\n",
            "Iter-8000; D_loss: 0.5213351249694824; G_loss: 3.262096881866455\n",
            "Iter-9000; D_loss: 0.8866742253303528; G_loss: 2.488405227661133\n",
            "Iter-10000; D_loss: 0.9080154299736023; G_loss: 3.0092363357543945\n",
            "Iter-11000; D_loss: 0.6964693665504456; G_loss: 2.545623540878296\n",
            "Iter-12000; D_loss: 0.7955878376960754; G_loss: 2.844303607940674\n",
            "Iter-13000; D_loss: 0.8184623718261719; G_loss: 2.97110915184021\n",
            "Iter-14000; D_loss: 0.5663131475448608; G_loss: 2.303577423095703\n",
            "Iter-15000; D_loss: 0.5788286924362183; G_loss: 2.2327280044555664\n",
            "Iter-16000; D_loss: 0.958774209022522; G_loss: 2.5011136531829834\n",
            "Iter-17000; D_loss: 0.7164368033409119; G_loss: 2.4847025871276855\n",
            "Iter-18000; D_loss: 1.1189721822738647; G_loss: 2.242116928100586\n",
            "Iter-19000; D_loss: 0.7555323839187622; G_loss: 2.0242419242858887\n",
            "Iter-20000; D_loss: 0.5732892751693726; G_loss: 1.9973958730697632\n",
            "Iter-21000; D_loss: 0.7043301463127136; G_loss: 2.103498697280884\n",
            "Iter-22000; D_loss: 0.7162018418312073; G_loss: 2.116551399230957\n",
            "Iter-23000; D_loss: 0.7298979163169861; G_loss: 1.7799593210220337\n",
            "Iter-24000; D_loss: 0.6302523612976074; G_loss: 1.9384435415267944\n",
            "Iter-25000; D_loss: 0.9067971706390381; G_loss: 1.8640998601913452\n",
            "Iter-26000; D_loss: 0.9050723314285278; G_loss: 1.9872900247573853\n",
            "Iter-27000; D_loss: 0.7642608880996704; G_loss: 2.039008855819702\n",
            "Iter-28000; D_loss: 0.8529741764068604; G_loss: 2.1465461254119873\n",
            "Iter-29000; D_loss: 0.6172160506248474; G_loss: 2.290665626525879\n",
            "Iter-30000; D_loss: 0.685725748538971; G_loss: 1.9231865406036377\n",
            "Iter-31000; D_loss: 0.7773740291595459; G_loss: 2.145728588104248\n",
            "Iter-32000; D_loss: 0.8408880233764648; G_loss: 2.576000690460205\n",
            "Iter-33000; D_loss: 0.6527872085571289; G_loss: 2.00712251663208\n",
            "Iter-34000; D_loss: 0.778430700302124; G_loss: 2.187800407409668\n",
            "Iter-35000; D_loss: 0.7824652194976807; G_loss: 2.3395543098449707\n",
            "Iter-36000; D_loss: 0.6551655530929565; G_loss: 2.1582276821136475\n",
            "Iter-37000; D_loss: 0.6200697422027588; G_loss: 2.2969233989715576\n",
            "Iter-38000; D_loss: 0.6722981929779053; G_loss: 2.3166680335998535\n",
            "Iter-39000; D_loss: 0.8634998202323914; G_loss: 2.077758550643921\n",
            "Iter-40000; D_loss: 0.7879692912101746; G_loss: 2.4780185222625732\n",
            "Iter-41000; D_loss: 0.8492242097854614; G_loss: 2.6704161167144775\n",
            "Iter-42000; D_loss: 0.6058871150016785; G_loss: 2.8187527656555176\n",
            "Iter-43000; D_loss: 0.6173339486122131; G_loss: 2.5656731128692627\n",
            "Iter-44000; D_loss: 0.6479405760765076; G_loss: 2.21105694770813\n",
            "Iter-45000; D_loss: 0.7144704461097717; G_loss: 2.5949742794036865\n",
            "Iter-46000; D_loss: 0.7432040572166443; G_loss: 2.31996488571167\n",
            "Iter-47000; D_loss: 0.6141421794891357; G_loss: 2.508676290512085\n",
            "Iter-48000; D_loss: 0.7896695733070374; G_loss: 2.2241809368133545\n",
            "Iter-49000; D_loss: 0.7851369380950928; G_loss: 2.2463572025299072\n",
            "Iter-50000; D_loss: 0.6243670582771301; G_loss: 2.5050606727600098\n",
            "Iter-51000; D_loss: 0.5814540982246399; G_loss: 2.4255895614624023\n",
            "Iter-52000; D_loss: 0.7707489132881165; G_loss: 2.50168776512146\n",
            "Iter-53000; D_loss: 0.6284903287887573; G_loss: 2.6609606742858887\n",
            "Iter-54000; D_loss: 0.6976408958435059; G_loss: 2.6614699363708496\n",
            "Iter-55000; D_loss: 0.7356778383255005; G_loss: 2.3822133541107178\n",
            "Iter-56000; D_loss: 0.6322615146636963; G_loss: 2.60014271736145\n",
            "Iter-57000; D_loss: 0.543511688709259; G_loss: 2.9012982845306396\n",
            "Iter-58000; D_loss: 0.5516459941864014; G_loss: 2.3626515865325928\n",
            "Iter-59000; D_loss: 0.390718549489975; G_loss: 1.9873214960098267\n",
            "Iter-60000; D_loss: 0.6584580540657043; G_loss: 2.0480427742004395\n",
            "Iter-61000; D_loss: 0.6325697302818298; G_loss: 2.1310651302337646\n",
            "Iter-62000; D_loss: 0.703395664691925; G_loss: 2.0153276920318604\n",
            "Iter-63000; D_loss: 0.6470462679862976; G_loss: 2.4428086280822754\n",
            "Iter-64000; D_loss: 0.6323182582855225; G_loss: 2.3649916648864746\n",
            "Iter-65000; D_loss: 0.715968906879425; G_loss: 2.7724695205688477\n",
            "Iter-66000; D_loss: 0.7669434547424316; G_loss: 2.731743097305298\n",
            "Iter-67000; D_loss: 0.5863630175590515; G_loss: 2.5493173599243164\n",
            "Iter-68000; D_loss: 0.5430068969726562; G_loss: 2.553323268890381\n",
            "Iter-69000; D_loss: 0.6394598484039307; G_loss: 2.0071630477905273\n",
            "Iter-70000; D_loss: 0.7057769298553467; G_loss: 2.2063660621643066\n",
            "Iter-71000; D_loss: 0.697920560836792; G_loss: 2.3046064376831055\n",
            "Iter-72000; D_loss: 0.5231587290763855; G_loss: 2.6825954914093018\n",
            "Iter-73000; D_loss: 0.490215539932251; G_loss: 2.55429744720459\n",
            "Iter-74000; D_loss: 0.5919231176376343; G_loss: 2.513179302215576\n",
            "Iter-75000; D_loss: 0.43495339155197144; G_loss: 3.1434812545776367\n",
            "Iter-76000; D_loss: 0.6609130501747131; G_loss: 2.7564380168914795\n",
            "Iter-77000; D_loss: 0.6237462162971497; G_loss: 2.172607660293579\n",
            "Iter-78000; D_loss: 0.48874202370643616; G_loss: 2.390641212463379\n",
            "Iter-79000; D_loss: 0.4709688723087311; G_loss: 2.5941720008850098\n",
            "Iter-80000; D_loss: 0.5656899809837341; G_loss: 2.814829111099243\n",
            "Iter-81000; D_loss: 0.5059224963188171; G_loss: 2.730071783065796\n",
            "Iter-82000; D_loss: 0.591511070728302; G_loss: 2.3681483268737793\n",
            "Iter-83000; D_loss: 0.5973333716392517; G_loss: 2.6853411197662354\n",
            "Iter-84000; D_loss: 0.6335814595222473; G_loss: 2.7227606773376465\n",
            "Iter-85000; D_loss: 0.46424978971481323; G_loss: 2.2838025093078613\n",
            "Iter-86000; D_loss: 0.6745306849479675; G_loss: 2.4875988960266113\n",
            "Iter-87000; D_loss: 0.593047022819519; G_loss: 2.3095879554748535\n",
            "Iter-88000; D_loss: 0.5755175948143005; G_loss: 2.2008252143859863\n",
            "Iter-89000; D_loss: 0.5463457703590393; G_loss: 2.4576995372772217\n",
            "Iter-90000; D_loss: 0.3382868766784668; G_loss: 2.469174861907959\n",
            "Iter-91000; D_loss: 0.631122350692749; G_loss: 2.5328269004821777\n",
            "Iter-92000; D_loss: 0.4078085720539093; G_loss: 2.4427318572998047\n",
            "Iter-93000; D_loss: 0.5069831013679504; G_loss: 2.1890928745269775\n",
            "Iter-94000; D_loss: 0.5152971744537354; G_loss: 2.8147850036621094\n",
            "Iter-95000; D_loss: 0.7774177193641663; G_loss: 2.4364047050476074\n",
            "Iter-96000; D_loss: 0.5924179553985596; G_loss: 2.322295665740967\n",
            "Iter-97000; D_loss: 0.4630719721317291; G_loss: 2.7220513820648193\n",
            "Iter-98000; D_loss: 0.6641350388526917; G_loss: 2.9902195930480957\n",
            "Iter-99000; D_loss: 0.3584800958633423; G_loss: 2.349419116973877\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn.functional as nn\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
        "mb_size = 64\n",
        "Z_dim = 100\n",
        "X_dim = mnist.train.images.shape[1]\n",
        "y_dim = mnist.train.labels.shape[1]\n",
        "h_dim = 128\n",
        "c = 0\n",
        "lr = 1e-3\n",
        "num_iterations = 100000\n",
        "\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
        "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)\n",
        "\n",
        "\n",
        "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
        "\n",
        "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
        "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
        "\n",
        "Whx = xavier_init(size=[h_dim, X_dim])\n",
        "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
        "\n",
        "\n",
        "def G(z):\n",
        "    h = nn.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
        "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
        "    return X\n",
        "\n",
        "\n",
        "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
        "\n",
        "Wxh = xavier_init(size=[X_dim, h_dim])\n",
        "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
        "\n",
        "Why = xavier_init(size=[h_dim, 1])\n",
        "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
        "\n",
        "\n",
        "def D(X):\n",
        "    h = nn.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
        "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
        "    return y\n",
        "\n",
        "\n",
        "G_params = [Wzh, bzh, Whx, bhx]\n",
        "D_params = [Wxh, bxh, Why, bhy]\n",
        "params = G_params + D_params\n",
        "\n",
        "\n",
        "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
        "\n",
        "\n",
        "def reset_grad():\n",
        "    for p in params:\n",
        "        if p.grad is not None:\n",
        "            data = p.grad.data\n",
        "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
        "\n",
        "\n",
        "G_solver = optim.Adam(G_params, lr=1e-3)\n",
        "D_solver = optim.Adam(D_params, lr=1e-3)\n",
        "\n",
        "ones_label = Variable(torch.ones(mb_size, 1))\n",
        "zeros_label = Variable(torch.zeros(mb_size, 1))\n",
        "\n",
        "\n",
        "for it in range(num_iterations):\n",
        "    # Sample data\n",
        "    z = Variable(torch.randn(mb_size, Z_dim))\n",
        "    X, _ = mnist.train.next_batch(mb_size)\n",
        "    X = Variable(torch.from_numpy(X))\n",
        "\n",
        "    # Dicriminator forward-loss-backward-update\n",
        "    G_sample = G(z)\n",
        "    D_real = D(X)\n",
        "    D_fake = D(G_sample)\n",
        "\n",
        "    # loss for task 1.1\n",
        "    D_loss = -torch.mean(torch.log(D_real) + torch.log(1. - D_fake))\n",
        "\n",
        "    # loss for task 1.2\n",
        "    #loss = torch.nn.BCEWithLogitsLoss()\n",
        "    #D_loss_real = loss(D_real, torch.ones_like(D_real))#(torch.nn.BCEWithLogitsLoss(D_real, torch.ones_like(D_real)))\n",
        "    #D_loss_fake = loss(D_fake, torch.zeros_like(D_fake))#(torch.nn.BCEWithLogitsLoss(D_fake, torch.zeros_like(D_fake)))\n",
        "    #D_loss = D_loss_real + D_loss_fake\n",
        "\n",
        "\n",
        "    D_loss.backward()\n",
        "    D_solver.step()\n",
        "\n",
        "    # Housekeeping - reset gradient\n",
        "    reset_grad()\n",
        "\n",
        "    # Generator forward-loss-backward-update\n",
        "    z = Variable(torch.randn(mb_size, Z_dim))\n",
        "    G_sample = G(z)\n",
        "    D_fake = D(G_sample)\n",
        "\n",
        "    # loss for task 1.1\n",
        "    G_loss = -torch.mean(torch.log(D_fake))\n",
        "    # loss for task 1.2\n",
        "    #G_loss = loss(D_fake, torch.ones_like(D_fake))\n",
        "\n",
        "    G_loss.backward()\n",
        "    G_solver.step()\n",
        "\n",
        "    # Housekeeping - reset gradient\n",
        "    reset_grad()\n",
        "\n",
        "    # Print and plot every now and then\n",
        "    if it % 1000 == 0:\n",
        "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
        "\n",
        "        samples = G(z).data.numpy()[:16]\n",
        "\n",
        "        fig = plt.figure(figsize=(4, 4))\n",
        "        gs = gridspec.GridSpec(4, 4)\n",
        "        gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for i, sample in enumerate(samples):\n",
        "            ax = plt.subplot(gs[i])\n",
        "            plt.axis('off')\n",
        "            ax.set_xticklabels([])\n",
        "            ax.set_yticklabels([])\n",
        "            ax.set_aspect('equal')\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        if not os.path.exists('out/'):\n",
        "            os.makedirs('out/')\n",
        "\n",
        "        plt.savefig('out/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "        c += 1\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip /content/out\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h0LpwguzGmdl",
        "outputId": "9cfbb9c7-cd1f-4dbe-fe8c-b579dc15b698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/out/ (stored 0%)\n",
            "updating: content/out/092.png (deflated 8%)\n",
            "updating: content/out/064.png (deflated 6%)\n",
            "updating: content/out/052.png (deflated 7%)\n",
            "updating: content/out/037.png (deflated 7%)\n",
            "updating: content/out/067.png (deflated 6%)\n",
            "updating: content/out/086.png (deflated 8%)\n",
            "updating: content/out/077.png (deflated 6%)\n",
            "updating: content/out/030.png (deflated 6%)\n",
            "updating: content/out/074.png (deflated 7%)\n",
            "updating: content/out/005.png (deflated 6%)\n",
            "updating: content/out/016.png (deflated 7%)\n",
            "updating: content/out/025.png (deflated 6%)\n",
            "updating: content/out/000.png (deflated 8%)\n",
            "updating: content/out/043.png (deflated 6%)\n",
            "updating: content/out/072.png (deflated 6%)\n",
            "updating: content/out/065.png (deflated 7%)\n",
            "updating: content/out/015.png (deflated 6%)\n",
            "updating: content/out/012.png (deflated 6%)\n",
            "updating: content/out/093.png (deflated 7%)\n",
            "updating: content/out/091.png (deflated 7%)\n",
            "updating: content/out/087.png (deflated 8%)\n",
            "updating: content/out/024.png (deflated 6%)\n",
            "updating: content/out/039.png (deflated 6%)\n",
            "updating: content/out/027.png (deflated 6%)\n",
            "updating: content/out/083.png (deflated 7%)\n",
            "updating: content/out/021.png (deflated 7%)\n",
            "updating: content/out/042.png (deflated 6%)\n",
            "updating: content/out/048.png (deflated 6%)\n",
            "updating: content/out/084.png (deflated 8%)\n",
            "updating: content/out/017.png (deflated 6%)\n",
            "updating: content/out/069.png (deflated 7%)\n",
            "updating: content/out/055.png (deflated 6%)\n",
            "updating: content/out/076.png (deflated 7%)\n",
            "updating: content/out/054.png (deflated 7%)\n",
            "updating: content/out/059.png (deflated 8%)\n",
            "updating: content/out/014.png (deflated 6%)\n",
            "updating: content/out/070.png (deflated 6%)\n",
            "updating: content/out/098.png (deflated 8%)\n",
            "updating: content/out/033.png (deflated 7%)\n",
            "updating: content/out/029.png (deflated 6%)\n",
            "updating: content/out/019.png (deflated 6%)\n",
            "updating: content/out/049.png (deflated 6%)\n",
            "updating: content/out/041.png (deflated 6%)\n",
            "updating: content/out/044.png (deflated 7%)\n",
            "updating: content/out/007.png (deflated 6%)\n",
            "updating: content/out/061.png (deflated 6%)\n",
            "updating: content/out/034.png (deflated 7%)\n",
            "updating: content/out/088.png (deflated 6%)\n",
            "updating: content/out/062.png (deflated 7%)\n",
            "updating: content/out/078.png (deflated 8%)\n",
            "updating: content/out/001.png (deflated 7%)\n",
            "updating: content/out/003.png (deflated 6%)\n",
            "updating: content/out/085.png (deflated 6%)\n",
            "updating: content/out/022.png (deflated 6%)\n",
            "updating: content/out/063.png (deflated 7%)\n",
            "updating: content/out/002.png (deflated 7%)\n",
            "updating: content/out/090.png (deflated 8%)\n",
            "updating: content/out/095.png (deflated 6%)\n",
            "updating: content/out/097.png (deflated 8%)\n",
            "updating: content/out/057.png (deflated 6%)\n",
            "updating: content/out/008.png (deflated 6%)\n",
            "updating: content/out/023.png (deflated 6%)\n",
            "updating: content/out/081.png (deflated 8%)\n",
            "updating: content/out/046.png (deflated 6%)\n",
            "updating: content/out/010.png (deflated 6%)\n",
            "updating: content/out/066.png (deflated 6%)\n",
            "updating: content/out/013.png (deflated 6%)\n",
            "updating: content/out/071.png (deflated 6%)\n",
            "updating: content/out/018.png (deflated 7%)\n",
            "updating: content/out/036.png (deflated 6%)\n",
            "updating: content/out/073.png (deflated 6%)\n",
            "updating: content/out/040.png (deflated 6%)\n",
            "updating: content/out/006.png (deflated 6%)\n",
            "updating: content/out/032.png (deflated 7%)\n",
            "updating: content/out/045.png (deflated 6%)\n",
            "updating: content/out/058.png (deflated 6%)\n",
            "updating: content/out/089.png (deflated 6%)\n",
            "updating: content/out/079.png (deflated 6%)\n",
            "updating: content/out/068.png (deflated 6%)\n",
            "updating: content/out/053.png (deflated 6%)\n",
            "updating: content/out/028.png (deflated 6%)\n",
            "updating: content/out/035.png (deflated 7%)\n",
            "updating: content/out/026.png (deflated 6%)\n",
            "updating: content/out/075.png (deflated 7%)\n",
            "updating: content/out/060.png (deflated 6%)\n",
            "updating: content/out/009.png (deflated 6%)\n",
            "updating: content/out/094.png (deflated 7%)\n",
            "updating: content/out/011.png (deflated 6%)\n",
            "updating: content/out/080.png (deflated 6%)\n",
            "updating: content/out/096.png (deflated 7%)\n",
            "updating: content/out/031.png (deflated 6%)\n",
            "updating: content/out/099.png (deflated 6%)\n",
            "updating: content/out/082.png (deflated 7%)\n",
            "updating: content/out/020.png (deflated 7%)\n",
            "updating: content/out/004.png (deflated 6%)\n",
            "updating: content/out/051.png (deflated 7%)\n",
            "updating: content/out/047.png (deflated 6%)\n",
            "updating: content/out/050.png (deflated 7%)\n",
            "updating: content/out/038.png (deflated 6%)\n",
            "updating: content/out/056.png (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7c6c8e8c-3a92-4826-84f4-c75b86f7afa7\", \"file.zip\", 3187812)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}